# ğŸ’¬ SMS Spam Classifier (NLP â€“ Easy Project)

A clean, reproducible **Spam vs Ham** SMS classifier that demonstrates end-to-end NLP workflow â€” from data cleaning and EDA to modeling, evaluation, and interpretability.

---

## ğŸ§  Overview
**Task:** Binary text classification (_spam_ vs _ham_) on the classic **SMS Spam Collection** dataset (5,574 messages).  
**Approach:** `TF-IDF` features (unigrams + bigrams) â†’ `Logistic Regression` baseline.  
**Why it matters:** Provides a strong, interpretable baseline â€” ideal for discussing **precision vs recall**, **threshold tuning**, and **deployment considerations**.

---

## ğŸ“Š Model Performance

| Split | Accuracy | Spam Precision | Spam Recall | F1 (Spam) | ROC-AUC |
|:------|----------:|---------------:|-------------:|----------:|--------:|
| **Validation** | 0.968 | 1.000 | 0.759 | 0.863 | **0.996** |
| **Test** | 0.962 | 1.000 | 0.714 | 0.833 | **0.986** |

ğŸ§© **Interpretation:**  
The model achieves **very high precision** (few false positives) but **lower recall** (some missed spam). Use threshold tuning (see Notebook `03_threshold_tuning.ipynb`) to optimize this trade-off.

---

## ğŸ“ˆ Key Visualizations

<table>
<tr>
<th>ROC Curve</th>
<th>Confusion Matrix</th>
</tr>
<tr>
<td><img src="reports/figures/roc_test.png" width="90%"/></td>
<td><img src="reports/figures/confusion_matrix_test.png" width="90%"/></td>
</tr>
</table>

---

## ğŸ§° Project Structure

```
sms-spam-classifier/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/SMSSpamCollection        # raw dataset (TSV: label \t text)
â”‚   â””â”€â”€ processed/                   # optional train/val/test splits
â”œâ”€â”€ models/
â”‚   â””â”€â”€ latest/model.joblib          # trained TF-IDF + LR pipeline
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_eval_plots.ipynb
â”‚   â””â”€â”€ 03_threshold_tuning.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/                     # exported plots
â”‚   â”œâ”€â”€ top_features_ham.txt
â”‚   â””â”€â”€ top_features_spam.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                     # train + evaluate + save model
â”‚   â”œâ”€â”€ infer.py                     # CLI scoring
â”‚   â””â”€â”€ top_ngrams.py                # inspect top weighted n-grams
â”œâ”€â”€ environment.yml                  # conda environment (recommended)
â”œâ”€â”€ requirements.txt                 # pip alternative
â””â”€â”€ README.md
```

---

## âš¡ Quickstart
```bash
# 0ï¸âƒ£ Create & activate environment
conda env create -f environment.yml
conda activate nlp-easy
# or
python -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt

# 1ï¸âƒ£ Place data (TSV format, no header)
#    Path: data/raw/SMSSpamCollection

# 2ï¸âƒ£ Train & evaluate
python src/train.py --data data/raw/SMSSpamCollection

# 3ï¸âƒ£ Inspect top features
python src/top_ngrams.py --model_dir models/latest --k 25

# 4ï¸âƒ£ Score new messages
python src/infer.py --model_dir models/latest --text "Free entry to win Â£1000!"
printf '%s\n%s\n' 'win cash now!!!' 'Hey, are we meeting at 5?' | python src/infer.py --model_dir models/latest
```

## ğŸ“˜ Interactive Notebooks (HTML Exports)

Explore the full workflow directly through rendered HTML notebooks (hosted in this repo):

- [**01_eda.html**](notebooks/exports/01_eda.html) â€“ Exploratory Data Analysis  
- [**02_eval_plots.html**](notebooks/exports/02_eval_plots.html) â€“ Model Evaluation (ROC, Confusion Matrix)  
- [**03_threshold_tuning.html**](notebooks/exports/03_threshold_tuning.html) â€“ Threshold Tuning & Precision-Recall Analysis
 
---

## ğŸ‘¤ Author

**Nursultan Azhimuratov**  
ğŸ“ PhD Candidate in Statistics | ğŸ’» Data Scientist  
ğŸ”— [GitHub: @drnursultan](https://github.com/drnursultan)
